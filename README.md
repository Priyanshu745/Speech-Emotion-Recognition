# ğŸ™ï¸ Speech Emotion Recognition Web App

This is a simple and interactive **Speech Emotion Detection** web application built with **Streamlit** and **TensorFlow**. Upload a `.wav` audio file and the app will predict the emotion conveyed in the speech using a pre-trained deep learning model.

---

## ğŸš€ Features

* ğŸ“ Upload `.wav` audio files
* ğŸ“ˆ Visualize waveform and mel-spectrogram
* ğŸ¤– Predict the speaker's emotion using a pre-trained CNN model
* ğŸ“Š Show class probabilities with human-readable emotion labels

---

## ğŸ›† Requirements

Before running the app, install the required dependencies:

```bash
pip install -r requirements.txt
```

**Main dependencies:**

* `streamlit`
* `tensorflow`
* `librosa`
* `matplotlib`
* `joblib`
* `numpy`

---

## ğŸ§ Model Info

* The model is a **Convolutional Neural Network (CNN)** trained on MFCC features extracted from audio clips.
* The labels are encoded using `LabelEncoder` and stored in `saved_model/label_encoder.pkl`.

---

## ğŸ“ Project Structure

```
speech-emotion-app/
â”‚
â”œâ”€â”€ app.py                     # Streamlit app code
â”œâ”€â”€ saved_model/
â”‚   â”œâ”€â”€ emotion_model.h5       # Trained Keras model
â”‚   â””â”€â”€ label_encoder.pkl      # Fitted label encoder
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run

1. Clone the repository:

```bash
git clone https://github.com/yourusername/speech-emotion-app.git
cd speech-emotion-app
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run the app:

```bash
streamlit run app.py
```

4. Open your browser and go to:
   `http://localhost:8501`

---

## ğŸ“· Screenshots

| Upload Audio                         | Emotion Prediction                     |
| ------------------------------------ | -------------------------------------- |
| ![upload](assets/upload_example.png) | ![predict](assets/predict_example.png) |

---

## ğŸ¯ Example Emotions

Supported emotion categories may include:

* Happy ğŸ˜Š
* Sad ğŸ˜¢
* Angry ğŸ˜ 
* Neutral ğŸ˜
  *(Custom depending on model training)*

---

## ğŸ“Œ Notes

* Audio must be in `.wav` format.
* Sampling rate is standardized to 16 kHz during preprocessing.
* The model expects MFCC features with shape `(174, 40)`.

---

## ğŸ§ª Future Improvements

* Live microphone recording
* Multilingual emotion support
* Real-time feedback or emotion timeline

---

## ğŸ›¡ï¸ License

MIT License â€” feel free to use, modify, and distribute.

---

## ğŸ¤ Credits

* [Streamlit](https://streamlit.io/)
* [Librosa](https://librosa.org/)
* [TensorFlow](https://www.tensorflow.org/)
